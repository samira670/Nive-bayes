{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uHYLO5UhhIb5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load the Iris dataset from UCI\n",
        "def load_iris_data():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "    response = urllib.request.urlopen(url)\n",
        "    data = pd.read_csv(response, header=None)\n",
        "\n",
        "    # Iris dataset has 4 features (columns 0-3) and the target class (column 4)\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].factorize()[0]  # Convert target class to integers (factorize)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "w4wjFLHchQJn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate Naive Bayes models\n",
        "def evaluate_models(X, y):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
        "\n",
        "    # Initialize the Naive Bayes models\n",
        "    bernoulli_nb = BernoulliNB(binarize=0.1)\n",
        "    multinomial_nb = MultinomialNB()\n",
        "    gaussian_nb = GaussianNB()\n",
        "\n",
        "    # Model names for display\n",
        "    models = [\n",
        "        ('BernoulliNB', bernoulli_nb),\n",
        "        ('MultinomialNB', multinomial_nb),\n",
        "        ('GaussianNB', gaussian_nb)\n",
        "    ]\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        print(f\"Results for {name}:\")\n",
        "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "        print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "        print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "        print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")"
      ],
      "metadata": {
        "id": "-8_XA41Wh1P0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "X, y = load_iris_data()\n",
        "\n",
        "# Evaluate the models\n",
        "evaluate_models(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpjM859ShUQC",
        "outputId": "baca5cbe-6a0c-4f0a-ff99-17a9822e2007"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for BernoulliNB:\n",
            "Accuracy: 0.4000\n",
            "Precision: 0.3724\n",
            "Recall: 0.4000\n",
            "F1 Score: 0.2600\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.14      0.25         7\n",
            "           1       0.38      1.00      0.55        11\n",
            "           2       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.40        30\n",
            "   macro avg       0.46      0.38      0.27        30\n",
            "weighted avg       0.37      0.40      0.26        30\n",
            "\n",
            "\n",
            "Results for MultinomialNB:\n",
            "Accuracy: 0.9667\n",
            "Precision: 0.9694\n",
            "Recall: 0.9667\n",
            "F1 Score: 0.9667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "\n",
            "Results for GaussianNB:\n",
            "Accuracy: 0.9667\n",
            "Precision: 0.9694\n",
            "Recall: 0.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}